{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "ollama": {
        "pkg-path": "ollama"
      },
      "ollama-ui": {
        "pkg-path": "nextjs-ollama-llm-ui"
      }
    },
    "vars": {
      "NEXT_PUBLIC_OLLAMA_URL": "http://localhost:11434"
    },
    "profile": {
      "common": "  if ollama list >/dev/null 2>&1; then\n    echo \"ü§ñ Ollama service running\"\n    echo \"üåê Web interface running on port 3000\"\n  else\n    echo \"‚õîÔ∏è Ollama service not available\"\n  fi\n"
    },
    "options": {
      "systems": [
        "aarch64-darwin",
        "aarch64-linux",
        "x86_64-linux",
        "x86_64-darwin"
      ],
      "cuda-detection": false
    },
    "services": {
      "ollama": {
        "command": "ollama serve"
      },
      "ollama-ui": {
        "command": "# wait for ollama to be ready\nuntil ollama list; do sleep 1; done\n\nexport NEXT_CACHE_DIR=\"$FLOX_ENV_CACHE/next\"\nmkdir -p $NEXT_CACHE_DIR\nnextjs-ollama-llm-ui\n"
      }
    }
  },
  "packages": [
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/4rixmk1pdxq5i3jvk1kvbw84gk2z4imm-ollama-0.9.1.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "ollama-0.9.1",
      "pname": "ollama",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T00:36:19.680857Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.1",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/spjq0y126d2d3js6czb54jgcnxrf3i8x-ollama-0.9.1"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/cbdb98byjwij6nk0cwgzgbmvcyi0b6mm-ollama-0.9.1.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "ollama-0.9.1",
      "pname": "ollama",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T00:55:00.751891Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.1",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/q5biz92m53hxmh1sgg9xgqgg7v2mg22w-ollama-0.9.1"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/z8hq1nv10db7dhssp1nknsgp6i04078z-ollama-0.9.1.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "ollama-0.9.1",
      "pname": "ollama",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T01:12:27.008114Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.1",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/vc6c2gvjvmw1d4xfk1d9i9lq31my8dbd-ollama-0.9.1"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/9s2j0fqfs1nlqnm55shfms9vnbflv6an-ollama-0.9.1.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "ollama-0.9.1",
      "pname": "ollama",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T01:32:42.611849Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.1",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/fdij59p03pikw99l3ahphhgrhkiz89kx-ollama-0.9.1"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/dp2lhf4igbpnbq72j5cpr1lg165z3hw3-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T00:36:18.788619Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/01fiab3wdig8gp1lzf05347j7ydahrs8-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/dvzmzaw1akjkp8yh79ny7jh0qiiwij3d-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T00:54:59.013566Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/rz2ycgj38hxgpzap5y8na4qy0kmzb5kz-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/84bk6jdhqzps51y53ymcjn8ip90vqdpw-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T01:12:26.109456Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/gzd9ygii32sh3594i7k527gp30xz9mw7-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/pnl44120q6r47a0f999x4ci8kr6w56wv-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "9e83b64f727c88a7711a2c463a7b16eedb69a84c",
      "rev_count": 816272,
      "rev_date": "2025-06-17T04:31:58Z",
      "scrape_date": "2025-06-18T01:32:40.641695Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/786l07dc90icli99glxvwiqz4aq9xjn9-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    }
  ]
}
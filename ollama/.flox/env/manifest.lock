{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "ollama": {
        "pkg-path": "ollama"
      },
      "ollama-ui": {
        "pkg-path": "nextjs-ollama-llm-ui"
      }
    },
    "vars": {
      "NEXT_PUBLIC_OLLAMA_URL": "http://localhost:11434"
    },
    "profile": {
      "common": "  if ollama list >/dev/null 2>&1; then\n    echo \"ü§ñ Ollama service running\"\n    echo \"üåê Web interface running on port 3000\"\n  else\n    echo \"‚õîÔ∏è Ollama service not available\"\n  fi\n"
    },
    "options": {
      "systems": [
        "aarch64-darwin",
        "aarch64-linux",
        "x86_64-linux",
        "x86_64-darwin"
      ],
      "cuda-detection": false
    },
    "services": {
      "ollama": {
        "command": "ollama serve"
      },
      "ollama-ui": {
        "command": "# wait for ollama to be ready\nuntil ollama list; do sleep 1; done\n\nexport NEXT_CACHE_DIR=\"$FLOX_ENV_CACHE/next\"\nmkdir -p $NEXT_CACHE_DIR\nnextjs-ollama-llm-ui\n"
      }
    }
  },
  "packages": [
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/90jsnvbg1fk31p8cmjh3k17jxflag7p5-ollama-0.11.7.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "ollama-0.11.7",
      "pname": "ollama",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:28:58.019037Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.11.7",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/k7bjbc9dkzzpmk1x83pyp37cq3i35jc5-ollama-0.11.7"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/kzxzjkr0a2d4q3fk241qxh353g3y320r-ollama-0.11.7.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "ollama-0.11.7",
      "pname": "ollama",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:37:30.215501Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.11.7",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/zc99j8sr0481xjyhkcsr6c57fk46r5a7-ollama-0.11.7"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/2jz492gw8hndgykr67fdpza9q6qplqls-ollama-0.11.7.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "ollama-0.11.7",
      "pname": "ollama",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:45:31.192185Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.11.7",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/hbr217wym28i6qxyn59gw5c80ih8492h-ollama-0.11.7"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/615133vhy06isah1g253ycl07llx922b-ollama-0.11.7.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "ollama-0.11.7",
      "pname": "ollama",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:53:08.929301Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.11.7",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/6vfxb3liai6vhgm6dxy7cv7cz6j871sn-ollama-0.11.7"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/gz2x7ykf6pkrqv45f76hgiah34pxkpgd-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:28:56.371085Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/d0vnvdxrfhx2z10kxg6plf9zsdz21c79-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/nixfnchs2lnrf16v48nkg1dbmaknd3da-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:37:27.196599Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/wqj1mbd5ncqs6h3bfl82d6c5368lx425-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/4ifi3lsyfnsvnpm99975ky1qg2bijx8b-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:45:29.487672Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/kifxaqsh1azzf8sdmkwa50aly479p1qp-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/64acxq65xiqmw3lid8rxy80ly7zphjd4-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=d7600c775f877cd87b4f5a831c28aa94137377aa",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "d7600c775f877cd87b4f5a831c28aa94137377aa",
      "rev_count": 854036,
      "rev_date": "2025-08-30T08:25:00Z",
      "scrape_date": "2025-08-31T03:53:05.835988Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/hr6hw9fwl19758mq3s5inc119i2jy26w-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    }
  ]
}
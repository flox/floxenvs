{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "ollama": {
        "pkg-path": "ollama"
      },
      "ollama-ui": {
        "pkg-path": "nextjs-ollama-llm-ui"
      }
    },
    "vars": {
      "NEXT_PUBLIC_OLLAMA_URL": "http://localhost:11434"
    },
    "profile": {
      "common": "  if ollama list >/dev/null 2>&1; then\n    echo \"ü§ñ Ollama service running\"\n    echo \"üåê Web interface running on port 3000\"\n  else\n    echo \"‚õîÔ∏è Ollama service not available\"\n  fi\n"
    },
    "options": {
      "systems": [
        "aarch64-darwin",
        "aarch64-linux",
        "x86_64-linux",
        "x86_64-darwin"
      ],
      "cuda-detection": false
    },
    "services": {
      "ollama": {
        "command": "ollama serve"
      },
      "ollama-ui": {
        "command": "# wait for ollama to be ready\nuntil ollama list; do sleep 1; done\n\nexport NEXT_CACHE_DIR=\"$FLOX_ENV_CACHE/next\"\nmkdir -p $NEXT_CACHE_DIR\nnextjs-ollama-llm-ui\n"
      }
    }
  },
  "packages": [
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/sf8gfpqfbgcs4390r429fn332qryrcjz-ollama-0.6.4.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "ollama-0.6.4",
      "pname": "ollama",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T01:14:41.476379Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.4",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/fhj5k6b7s3l6rjd7lgl5xavgpfdbvbdb-ollama-0.6.4"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/fsvq68b19ik59vmwcs2zbi4xqqwfia4p-ollama-0.6.4.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "ollama-0.6.4",
      "pname": "ollama",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T01:35:40.301263Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.4",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/dj2ml46fsbbsr7xn8786n2cvdxnqnlgl-ollama-0.6.4"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/k78jciz9v9lnp1iw3iya1mi5cplca14s-ollama-0.6.4.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "ollama-0.6.4",
      "pname": "ollama",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T02:16:29.052846Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.4",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/b6zbghvhwsa9l8d5vkpwsf4bkn63a8ls-ollama-0.6.4"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/rlp6d1j8dppkx39qnf78vcrinljhjq1i-ollama-0.6.4.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "ollama-0.6.4",
      "pname": "ollama",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T01:54:10.844794Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.4",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/qabjk12cs1l1mwriy2566x7z1jqlfccy-ollama-0.6.4"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/7kxkcsajsp5908g4k965zd3mgfiar7sj-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T01:14:40.720350Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/jpkl50ydssf6q958dpffy600mr84n321-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/y4bckips9z4hv3csi96ynm8d86xm6zsn-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T01:35:38.780142Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/yyxhc338lhihgc1r902mrqv7ha6pi3rz-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/x35789md5pihw64fnly8z2kgnrcrjcmm-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T02:16:27.358989Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/26cfwiwxji2picv5r9wx53bc9im6yma4-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/7bq6nm0zqyxsv3206n3fasn1bvfpz5mn-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "063dece00c5a77e4a0ea24e5e5a5bd75232806f8",
      "rev_count": 780010,
      "rev_date": "2025-04-06T18:34:07Z",
      "scrape_date": "2025-04-08T01:54:10.072767Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/cfrrfiir2ph1lk1ap3g26b6hq0n26vcn-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    }
  ]
}
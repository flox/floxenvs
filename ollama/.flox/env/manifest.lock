{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "ollama": {
        "pkg-path": "ollama"
      },
      "ollama-ui": {
        "pkg-path": "nextjs-ollama-llm-ui"
      }
    },
    "vars": {
      "NEXT_PUBLIC_OLLAMA_URL": "http://localhost:11434"
    },
    "profile": {
      "common": "  if ollama list >/dev/null 2>&1; then\n    echo \"ü§ñ Ollama service running\"\n    echo \"üåê Web interface running on port 3000\"\n  else\n    echo \"‚õîÔ∏è Ollama service not available\"\n  fi\n"
    },
    "options": {
      "systems": [
        "aarch64-darwin",
        "aarch64-linux",
        "x86_64-linux",
        "x86_64-darwin"
      ],
      "cuda-detection": false
    },
    "services": {
      "ollama": {
        "command": "ollama serve"
      },
      "ollama-ui": {
        "command": "# wait for ollama to be ready\nuntil ollama list; do sleep 1; done\n\nexport NEXT_CACHE_DIR=\"$FLOX_ENV_CACHE/next\"\nmkdir -p $NEXT_CACHE_DIR\nnextjs-ollama-llm-ui\n"
      }
    }
  },
  "packages": [
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/9k5xw2cxhiark7fwhfa0h1lsn3ibidaj-ollama-0.9.6.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "ollama-0.9.6",
      "pname": "ollama",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T00:32:27.975766Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.6",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/lw5dhd09v2gfn540qhm3636vgpcx9x0i-ollama-0.9.6"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/fdgnvza4ag5dq0xprz050cr7mhkvqrk8-ollama-0.9.6.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "ollama-0.9.6",
      "pname": "ollama",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T00:58:14.659250Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.6",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/j7m16skf27wxcjz1g2rmvyn5rg6hykgz-ollama-0.9.6"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/ln4sc7rq7q3cpah0xivkc5hrvmrnhdw6-ollama-0.9.6.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "ollama-0.9.6",
      "pname": "ollama",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T01:21:15.726186Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.6",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/z43ipc5mxc9dgdvj3jsyhnsdwrh1478d-ollama-0.9.6"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/1bvl4y8cdw03fcchymgbpwzck6pwfwsa-ollama-0.9.6.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "ollama-0.9.6",
      "pname": "ollama",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T01:48:36.893559Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "0.9.6",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/cxjqisk8pnda2bycvk1aci6j512qkgzz-ollama-0.9.6"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/1klkmj4kq8r42fiqqbf9dip1sfcsc90g-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T00:32:27.102844Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/6i02yldg1r59y1p4f5paq36mbfs8np4y-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/p73bmahrg2z5445r6cimakkk7rq1mkbg-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T00:58:12.990715Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/riw99l2jc9c46sx27nilbk39mbkxknp8-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/wl58lcqb1lp8w6dkz4kdivm7qc5jflrn-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T01:21:14.830448Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/yaidlmg0bhsb850f5yswrwb4hms50v9r-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/m3dg8d47i1ag056xp64alq6yjqlm07sz-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6e987485eb2c77e5dcc5af4e3c70843711ef9251",
      "rev_count": 831064,
      "rev_date": "2025-07-16T17:35:22Z",
      "scrape_date": "2025-07-19T01:48:34.952651Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/6c0vfvdsykgpjcda2dhw0zxr1wzlzd5z-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    }
  ]
}
{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "ollama": {
        "pkg-path": "ollama"
      },
      "ollama-ui": {
        "pkg-path": "nextjs-ollama-llm-ui"
      }
    },
    "vars": {
      "NEXT_PUBLIC_OLLAMA_URL": "http://localhost:11434"
    },
    "hook": {},
    "profile": {
      "common": "  if ollama list >/dev/null 2>&1; then\n    echo \"ü§ñ Ollama service running\"\n    echo \"üåê Web interface running on port 3000\"\n  else\n    echo \"‚õîÔ∏è Ollama service not available\"\n  fi\n"
    },
    "options": {
      "systems": [
        "aarch64-darwin",
        "aarch64-linux",
        "x86_64-linux",
        "x86_64-darwin"
      ],
      "allow": {
        "licenses": []
      },
      "semver": {},
      "cuda-detection": false
    },
    "services": {
      "ollama": {
        "command": "ollama serve"
      },
      "ollama-ui": {
        "command": "# wait for ollama to be ready\nuntil ollama list; do sleep 1; done\n\nexport NEXT_CACHE_DIR=\"$FLOX_ENV_CACHE/next\"\nmkdir -p $NEXT_CACHE_DIR\nnextjs-ollama-llm-ui\n"
      }
    }
  },
  "packages": [
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/wb2h6ra0jc1wyja1rwyqsrr6bkwkvh68-ollama-0.6.0.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "ollama-0.6.0",
      "pname": "ollama",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/4rzms82qlvbqrzpx23xk6448bci2z10k-ollama-0.6.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/sfzfqmffibwxxy1ga0h1y75fcd3iwp5w-ollama-0.6.0.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "ollama-0.6.0",
      "pname": "ollama",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/9qxml0sxqdjam7my0b859hw3li50hr9s-ollama-0.6.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/by9y4qpm09n9l83c0fbv4sf18l91klnl-ollama-0.6.0.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "ollama-0.6.0",
      "pname": "ollama",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/mrd5g9y8z7jvbn8466ddpxsrya65fpk8-ollama-0.6.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/mc37sxjcmmn5l5xqykj6qiv1j0dckvp8-ollama-0.6.0.drv",
      "description": "Get up and running with large language models locally",
      "install_id": "ollama",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "ollama-0.6.0",
      "pname": "ollama",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "0.6.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/ch3lvf1k05h38xv2hs8id5hxmra2n5dv-ollama-0.6.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/djx2fls7b9438ncf4zdd05lxgwp9rkpl-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/wldlvq9dyirbh4ddi7l7p26pxa5av17j-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/v5g09wqyv1nnc1fhkj4h4zlcpw9psm90-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/5bk8zqb556rpjd8b4qfnvqwni1zlxkyq-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/5n388jsfkd12qing525anz53p3y9n8c1-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/50h0sla5b4byc6j8d7pn66sfszd30rfx-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nextjs-ollama-llm-ui",
      "broken": false,
      "derivation": "/nix/store/7zifqj4j6hl2pfxkvbmw78iq9njjnn7p-nextjs-ollama-llm-ui-1.2.0.drv",
      "description": "Simple chat web interface for Ollama LLMs",
      "install_id": "ollama-ui",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=6607cf789e541e7873d40d3a8f7815ea92204f32",
      "name": "nextjs-ollama-llm-ui-1.2.0",
      "pname": "nextjs-ollama-llm-ui",
      "rev": "6607cf789e541e7873d40d3a8f7815ea92204f32",
      "rev_count": 767267,
      "rev_date": "2025-03-13T07:39:42Z",
      "scrape_date": "2025-03-14T00:31:05Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "1.2.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/vv07960018igwn1f5p1476vqpj93sqbb-nextjs-ollama-llm-ui-1.2.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    }
  ]
}